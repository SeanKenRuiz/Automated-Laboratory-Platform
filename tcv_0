from ultralytics import YOLO
import cv2 as cv
import numpy as np
import torch

# Function to calculate orientation angle from YOLOv8 bounding box in xyxy format
def calculate_tray_orientation(frame, bbox):
    # bbox: [x_min, y_min, x_max, y_max] - YOLOv8 detection for the tray
    x_min, y_min, x_max, y_max = bbox
    
    # Calculate width and height from xyxy format
    w = x_max - x_min
    h = y_max - y_min

    # Create a mask or sub-image of the tray based on the bounding box
    tray_region = frame[y_min:y_max, x_min:x_max]
    
    # Convert to grayscale and apply edge detection
    gray = cv.cvtColor(tray_region, cv.COLOR_BGR2GRAY)
    edges = cv.Canny(gray, 50, 150)
    
    # Find contours
    contours, _ = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
    
    # If contours are detected, find the min area rectangle
    if contours:
        # Get the largest contour which should correspond to the tray
        largest_contour = max(contours, key=cv.contourArea)
        
        # Get the minimum area rectangle that can enclose the tray
        rect = cv.minAreaRect(largest_contour)
        box = cv.boxPoints(rect)
        box = np.int0(box)  # Convert to integer points
        
        # Draw the rectangle on the original image
        cv.drawContours(frame, [box + np.array([x_min, y_min])], 0, (0, 255, 0), 2)  # Offset the box back
        
        # The angle of the rectangle (rotation angle relative to the horizontal axis)
        angle = rect[-1]
        
        # The rect[-1] gives angle in range (-90, 0], we convert it to standard angle range [0, 180]
        if angle < -45:
            angle = 90 + angle
        else:
            angle = -angle
        
        return angle, frame
    
    return None, frame

# Access the webcam
cap = cv.VideoCapture(0)

# Load a pre-trained YOLOv10n model
model = YOLO("yolo_models/best_4.pt")

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

while True:
    # Capture frame-by-frame from the webcam
    ret, frame = cap.read()
    
    if not ret:
        print("Failed to grab frame.")
        break

    results = model.track(frame, persist=True, verbose=False, max_det=25, tracker="botsort.yaml")

    # Calculate tray orientation for the current frame
    angle, frame_with_rect = calculate_tray_orientation(frame, results[0].boxes.xyxy[(results[0].boxes.cls == 2).nonzero(as_tuple=True)[0]])

    # Display the angle on the frame
    if angle is not None:
        cv.putText(frame_with_rect, f'Angle: {angle:.2f} degrees', (50, 50), cv.FONT_HERSHEY_SIMPLEX, 
                    1, (0, 0, 255), 2, cv.LINE_AA)

    # Display the resulting frame
    cv.imshow('Tray Orientation', frame_with_rect)

    # Press 'q' to quit the webcam feed
    if cv.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close all OpenCV windows
cap.release()
cv.destroyAllWindows()
